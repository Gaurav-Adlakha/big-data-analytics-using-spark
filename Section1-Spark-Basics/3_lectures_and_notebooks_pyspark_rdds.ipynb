{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark notebook basics\n",
    "\n",
    "**SparkContext**: our way of comunicating to the Spark system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T14:53:53.777680Z",
     "start_time": "2018-07-02T14:53:53.770446Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T14:54:28.447291Z",
     "start_time": "2018-07-02T14:54:24.764850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master='local[4]')\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `master='local[4]` runs spark locally in my notebook using 4 workers (since I have 4 cores, we have one worker per core)\n",
    " \n",
    " We must have only one SparkContext at a time. It is designed for a single user. Before running a new SparkContext, stop the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T14:58:22.774558Z",
     "start_time": "2018-07-02T14:58:22.770460Z"
    }
   },
   "outputs": [],
   "source": [
    "# sc.stop() # stop current SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RDDs** (Resilient Distributed Dataset): a list of elements stored in several computers\n",
    "\n",
    "**Parallelize**: simplest wat of creating an RDD. It is of type `PythonRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:01:24.666175Z",
     "start_time": "2018-07-02T15:01:24.359064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=sc.parallelize(range(3))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collect**: RDD content is distributed among all executors. `collect()` is the inverse of `parallelize()`. Collects the elements of the RDD, returns a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:02:57.640852Z",
     "start_time": "2018-07-02T15:02:56.449752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "L=A.collect()\n",
    "print(type(L))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using collect eleminates the benefits of parallelism!!\n",
    "\n",
    "It is often tempting to `.collect()` an RDD to make it into a list, and then process it using standard Python. However, this means only the head node is performing the computation, thus not benefitting from Spark. Using RDD operations will make you use all the computers at your disposal\n",
    "\n",
    "**Map**: applies an operation to each element of the RDD. Parameter is the function defining the operation. Returns a new RDD. Operation is performed in parallel on all execution. Each executor operates on the local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:09:02.410694Z",
     "start_time": "2018-07-02T15:09:02.286156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.map(lambda x: x*x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce**: takes an RDD, return a single value. Reduce operator takes two elements as input and returns one as output. Repeatedly applies a reduce operator. Each executor reduces the data local to it. The results from all executors are combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:13:41.206190Z",
     "start_time": "2018-07-02T15:13:41.082349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:15:58.748807Z",
     "start_time": "2018-07-02T15:15:58.585335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds the shortest string\n",
    "words=['this','is','the','best','thinkpad','ever!']\n",
    "wordsRDD=sc.parallelize(words)\n",
    "wordsRDD.reduce(lambda w,v: w if len(w)<len(v) else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:19:23.954697Z",
     "start_time": "2018-07-02T15:19:23.828861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bad reduce operation\n",
    "B=sc.parallelize([1,3,5,2])\n",
    "B.reduce(lambda x,y: x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't an operation in which the order doesn't matter, because $x-y$ is different from $y-x$. Which of the following did you do:\n",
    "\n",
    "$$((1-3)-5)-2$$\n",
    "\n",
    "or\n",
    "\n",
    "$$(1-3)-(5-2)$$\n",
    "\n",
    "\n",
    "Using regular functions instead of lambda functions: lambda functions are short and sweet, but sometimes it is hard to use it in one line, we can use a full-fledged functions instead\n",
    "\n",
    "Suppose we want to find the last word in a lexigographical order among the longest words in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:24:47.601742Z",
     "start_time": "2018-07-02T15:24:47.584787Z"
    }
   },
   "outputs": [],
   "source": [
    "def largerThan(x,y):\n",
    "    if len(x)>len(y):\n",
    "        return x\n",
    "    elif len(y)>len(x):\n",
    "        return y\n",
    "    else:\n",
    "        if x>y:\n",
    "            return x\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T15:25:04.698602Z",
     "start_time": "2018-07-02T15:25:04.581728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thinkpad'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.reduce(largerThan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
